{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "21ed06dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.connect.session.SparkSession at 0x1c320612e00>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "  .remote(\"sc://192.168.1.7:15002\") \\\n",
    "  .appName(\"UDFTransformation\") \\\n",
    "  .config(\"spark.sql.ansi.enabled\", \"false\") \\\n",
    "  .config(\"spark.sql.execution.pythonUDF.arrow.enabled\", \"true\") \\\n",
    "  .config(\"spark.sql.repl.eagerEval.enabled\", \"true\") \\\n",
    "  .config(\"spark.sql.repl.eagerEval.truncate\", \"100\") \\\n",
    "  .getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa381bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.utils import IllegalArgumentException\n",
    "\n",
    "# lines = spark \\\n",
    "#     .readStream \\\n",
    "#     .format(\"rate\") \\\n",
    "#     .option(\"host\", \"192.168.1.7\") \\\n",
    "#     .option(\"port\", 9999) \\\n",
    "#     .load()\n",
    "\n",
    "lines = (spark.readStream\n",
    "  .format(\"rate\")\n",
    "  .option(\"rowsPerSecond\", 3)\n",
    "  .load()\n",
    ")\n",
    "try:\n",
    "  query = (lines.writeStream\n",
    "    .outputMode(\"update\")\n",
    "    .format(\"memory\")\n",
    "    .queryName(\"mem_results\")\n",
    "    .start()\n",
    "  )\n",
    "except IllegalArgumentException:\n",
    "  pass # already started\n",
    "import time\n",
    "\n",
    "if True:\n",
    "  for _ in range(20):\n",
    "    print(f\"{str(query.status):<100}\", end=\"\\r\")\n",
    "    time.sleep(0.1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f3f3d45f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>timestamp</th><th>value</th></tr>\n",
       "<tr><td>2025-10-25 19:19:26.691</td><td>23</td></tr>\n",
       "<tr><td>2025-10-25 19:19:26.357</td><td>22</td></tr>\n",
       "<tr><td>2025-10-25 19:19:26.024</td><td>21</td></tr>\n",
       "<tr><td>2025-10-25 19:19:25.691</td><td>20</td></tr>\n",
       "<tr><td>2025-10-25 19:19:25.357</td><td>19</td></tr>\n",
       "<tr><td>2025-10-25 19:19:25.024</td><td>18</td></tr>\n",
       "<tr><td>2025-10-25 19:19:24.691</td><td>17</td></tr>\n",
       "<tr><td>2025-10-25 19:19:24.357</td><td>16</td></tr>\n",
       "<tr><td>2025-10-25 19:19:24.024</td><td>15</td></tr>\n",
       "<tr><td>2025-10-25 19:19:23.691</td><td>14</td></tr>\n",
       "<tr><td>2025-10-25 19:19:23.357</td><td>13</td></tr>\n",
       "<tr><td>2025-10-25 19:19:23.024</td><td>12</td></tr>\n",
       "<tr><td>2025-10-25 19:19:22.691</td><td>11</td></tr>\n",
       "<tr><td>2025-10-25 19:19:22.357</td><td>10</td></tr>\n",
       "<tr><td>2025-10-25 19:19:22.024</td><td>9</td></tr>\n",
       "<tr><td>2025-10-25 19:19:21.691</td><td>8</td></tr>\n",
       "<tr><td>2025-10-25 19:19:21.357</td><td>7</td></tr>\n",
       "<tr><td>2025-10-25 19:19:21.024</td><td>6</td></tr>\n",
       "<tr><td>2025-10-25 19:19:20.691</td><td>5</td></tr>\n",
       "<tr><td>2025-10-25 19:19:20.357</td><td>4</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+-----------------------+-----+\n",
       "|              timestamp|value|\n",
       "+-----------------------+-----+\n",
       "|2025-10-25 19:19:26.691|   23|\n",
       "|2025-10-25 19:19:26.357|   22|\n",
       "|2025-10-25 19:19:26.024|   21|\n",
       "|2025-10-25 19:19:25.691|   20|\n",
       "|2025-10-25 19:19:25.357|   19|\n",
       "|2025-10-25 19:19:25.024|   18|\n",
       "|2025-10-25 19:19:24.691|   17|\n",
       "|2025-10-25 19:19:24.357|   16|\n",
       "|2025-10-25 19:19:24.024|   15|\n",
       "|2025-10-25 19:19:23.691|   14|\n",
       "|2025-10-25 19:19:23.357|   13|\n",
       "|2025-10-25 19:19:23.024|   12|\n",
       "|2025-10-25 19:19:22.691|   11|\n",
       "|2025-10-25 19:19:22.357|   10|\n",
       "|2025-10-25 19:19:22.024|    9|\n",
       "|2025-10-25 19:19:21.691|    8|\n",
       "|2025-10-25 19:19:21.357|    7|\n",
       "|2025-10-25 19:19:21.024|    6|\n",
       "|2025-10-25 19:19:20.691|    5|\n",
       "|2025-10-25 19:19:20.357|    4|\n",
       "+-----------------------+-----+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select * from mem_results order by value desc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6a079545",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mquery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mawaitTermination\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Plancha\\spark-labs\\.venv\\lib\\site-packages\\pyspark\\sql\\connect\\streaming\\query.py:92\u001b[0m, in \u001b[0;36mStreamingQuery.awaitTermination\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m PySparkValueError(\n\u001b[0;32m     88\u001b[0m             errorClass\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVALUE_NOT_POSITIVE\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     89\u001b[0m             messageParameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_value\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(timeout)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[0;32m     90\u001b[0m         )\n\u001b[0;32m     91\u001b[0m     cmd\u001b[38;5;241m.\u001b[39mawait_termination\u001b[38;5;241m.\u001b[39mtimeout_ms \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(timeout \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m)\n\u001b[1;32m---> 92\u001b[0m     terminated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_streaming_query_cmd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mawait_termination\u001b[38;5;241m.\u001b[39mterminated\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m terminated\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Plancha\\spark-labs\\.venv\\lib\\site-packages\\pyspark\\sql\\connect\\streaming\\query.py:185\u001b[0m, in \u001b[0;36mStreamingQuery._execute_streaming_query_cmd\u001b[1;34m(self, cmd)\u001b[0m\n\u001b[0;32m    183\u001b[0m exec_cmd \u001b[38;5;241m=\u001b[39m pb2\u001b[38;5;241m.\u001b[39mCommand()\n\u001b[0;32m    184\u001b[0m exec_cmd\u001b[38;5;241m.\u001b[39mstreaming_query_command\u001b[38;5;241m.\u001b[39mCopyFrom(cmd)\n\u001b[1;32m--> 185\u001b[0m (_, properties, _) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexec_cmd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(pb2\u001b[38;5;241m.\u001b[39mStreamingQueryCommandResult, properties[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstreaming_query_command_result\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\Plancha\\spark-labs\\.venv\\lib\\site-packages\\pyspark\\sql\\connect\\client\\core.py:1148\u001b[0m, in \u001b[0;36mSparkConnectClient.execute_command\u001b[1;34m(self, command, observations)\u001b[0m\n\u001b[0;32m   1146\u001b[0m     req\u001b[38;5;241m.\u001b[39muser_context\u001b[38;5;241m.\u001b[39muser_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_user_id\n\u001b[0;32m   1147\u001b[0m req\u001b[38;5;241m.\u001b[39mplan\u001b[38;5;241m.\u001b[39mcommand\u001b[38;5;241m.\u001b[39mCopyFrom(command)\n\u001b[1;32m-> 1148\u001b[0m data, _, metrics, observed_metrics, properties \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_and_fetch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobservations\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m   1150\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1151\u001b[0m \u001b[38;5;66;03m# Create a query execution object.\u001b[39;00m\n\u001b[0;32m   1152\u001b[0m ei \u001b[38;5;241m=\u001b[39m ExecutionInfo(metrics, observed_metrics)\n",
      "File \u001b[1;32mc:\\Users\\Plancha\\spark-labs\\.venv\\lib\\site-packages\\pyspark\\sql\\connect\\client\\core.py:1560\u001b[0m, in \u001b[0;36mSparkConnectClient._execute_and_fetch\u001b[1;34m(self, req, observations, self_destruct)\u001b[0m\n\u001b[0;32m   1557\u001b[0m properties: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Progress(handlers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_progress_handlers, operation_id\u001b[38;5;241m=\u001b[39mreq\u001b[38;5;241m.\u001b[39moperation_id) \u001b[38;5;28;01mas\u001b[39;00m progress:\n\u001b[1;32m-> 1560\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_and_fetch_as_iterator(\n\u001b[0;32m   1561\u001b[0m         req, observations, progress\u001b[38;5;241m=\u001b[39mprogress\n\u001b[0;32m   1562\u001b[0m     ):\n\u001b[0;32m   1563\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, StructType):\n\u001b[0;32m   1564\u001b[0m             schema \u001b[38;5;241m=\u001b[39m response\n",
      "File \u001b[1;32mc:\\Users\\Plancha\\spark-labs\\.venv\\lib\\site-packages\\pyspark\\sql\\connect\\client\\core.py:1535\u001b[0m, in \u001b[0;36mSparkConnectClient._execute_and_fetch_as_iterator\u001b[1;34m(self, req, observations, progress)\u001b[0m\n\u001b[0;32m   1533\u001b[0m         progress\u001b[38;5;241m.\u001b[39mfinish()\n\u001b[0;32m   1534\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterrupt_operation(req\u001b[38;5;241m.\u001b[39moperation_id)\n\u001b[1;32m-> 1535\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m kb\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[0;32m   1537\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_error(error)\n",
      "File \u001b[1;32mc:\\Users\\Plancha\\spark-labs\\.venv\\lib\\site-packages\\pyspark\\sql\\connect\\client\\core.py:1523\u001b[0m, in \u001b[0;36mSparkConnectClient._execute_and_fetch_as_iterator\u001b[1;34m(self, req, observations, progress)\u001b[0m\n\u001b[0;32m   1518\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_reattachable_execute:\n\u001b[0;32m   1519\u001b[0m     \u001b[38;5;66;03m# Don't use retryHandler - own retry handling is inside.\u001b[39;00m\n\u001b[0;32m   1520\u001b[0m     generator \u001b[38;5;241m=\u001b[39m ExecutePlanResponseReattachableIterator(\n\u001b[0;32m   1521\u001b[0m         req, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stub, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrying, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_builder\u001b[38;5;241m.\u001b[39mmetadata()\n\u001b[0;32m   1522\u001b[0m     )\n\u001b[1;32m-> 1523\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m generator:\n\u001b[0;32m   1524\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m handle_response(b)\n\u001b[0;32m   1525\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\uv\\data\\python\\cpython-3.10.18-windows-x86_64-none\\lib\\_collections_abc.py:330\u001b[0m, in \u001b[0;36mGenerator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    327\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the next item from the generator.\u001b[39;00m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;124;03m    When exhausted, raise StopIteration.\u001b[39;00m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 330\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Plancha\\spark-labs\\.venv\\lib\\site-packages\\pyspark\\sql\\connect\\client\\reattach.py:138\u001b[0m, in \u001b[0;36mExecutePlanResponseReattachableIterator.send\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msend\u001b[39m(\u001b[38;5;28mself\u001b[39m, value: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pb2\u001b[38;5;241m.\u001b[39mExecutePlanResponse:\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;66;03m# will trigger reattach in case the stream completed without result_complete\u001b[39;00m\n\u001b[1;32m--> 138\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_has_next\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    139\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m()\n\u001b[0;32m    141\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current\n",
      "File \u001b[1;32mc:\\Users\\Plancha\\spark-labs\\.venv\\lib\\site-packages\\pyspark\\sql\\connect\\client\\reattach.py:162\u001b[0m, in \u001b[0;36mExecutePlanResponseReattachableIterator._has_next\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 162\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_iter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    166\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Plancha\\spark-labs\\.venv\\lib\\site-packages\\pyspark\\sql\\connect\\client\\reattach.py:261\u001b[0m, in \u001b[0;36mExecutePlanResponseReattachableIterator._call_iter\u001b[1;34m(self, iter_fun)\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(\n\u001b[0;32m    255\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stub\u001b[38;5;241m.\u001b[39mReattachExecute(\n\u001b[0;32m    256\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_reattach_execute_request(), metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[0;32m    257\u001b[0m         )\n\u001b[0;32m    258\u001b[0m     )\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 261\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43miter_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    263\u001b[0m     status \u001b[38;5;241m=\u001b[39m rpc_status\u001b[38;5;241m.\u001b[39mfrom_call(cast(grpc\u001b[38;5;241m.\u001b[39mCall, e))\n",
      "File \u001b[1;32mc:\\Users\\Plancha\\spark-labs\\.venv\\lib\\site-packages\\pyspark\\sql\\connect\\client\\reattach.py:163\u001b[0m, in \u001b[0;36mExecutePlanResponseReattachableIterator._has_next.<locals>.<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_iter(\n\u001b[1;32m--> 163\u001b[0m             \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    164\u001b[0m         )\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    166\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Plancha\\spark-labs\\.venv\\lib\\site-packages\\grpc\\_channel.py:543\u001b[0m, in \u001b[0;36m_Rendezvous.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 543\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Plancha\\spark-labs\\.venv\\lib\\site-packages\\grpc\\_channel.py:963\u001b[0m, in \u001b[0;36m_MultiThreadedRendezvous._next\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    957\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_response_ready\u001b[39m():\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state\u001b[38;5;241m.\u001b[39mresponse \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m    959\u001b[0m         cygrpc\u001b[38;5;241m.\u001b[39mOperationType\u001b[38;5;241m.\u001b[39mreceive_message \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state\u001b[38;5;241m.\u001b[39mdue\n\u001b[0;32m    960\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state\u001b[38;5;241m.\u001b[39mcode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    961\u001b[0m     )\n\u001b[1;32m--> 963\u001b[0m \u001b[43m_common\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcondition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_response_ready\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state\u001b[38;5;241m.\u001b[39mresponse \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    965\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state\u001b[38;5;241m.\u001b[39mresponse\n",
      "File \u001b[1;32mc:\\Users\\Plancha\\spark-labs\\.venv\\lib\\site-packages\\grpc\\_common.py:156\u001b[0m, in \u001b[0;36mwait\u001b[1;34m(wait_fn, wait_complete_fn, timeout, spin_cb)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m wait_complete_fn():\n\u001b[1;32m--> 156\u001b[0m         \u001b[43m_wait_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMAXIMUM_WAIT_TIMEOUT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspin_cb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    158\u001b[0m     end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m+\u001b[39m timeout\n",
      "File \u001b[1;32mc:\\Users\\Plancha\\spark-labs\\.venv\\lib\\site-packages\\grpc\\_common.py:116\u001b[0m, in \u001b[0;36m_wait_once\u001b[1;34m(wait_fn, timeout, spin_cb)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_wait_once\u001b[39m(\n\u001b[0;32m    112\u001b[0m     wait_fn: Callable[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;28mbool\u001b[39m],\n\u001b[0;32m    113\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m,\n\u001b[0;32m    114\u001b[0m     spin_cb: Optional[Callable[[], \u001b[38;5;28;01mNone\u001b[39;00m]],\n\u001b[0;32m    115\u001b[0m ):\n\u001b[1;32m--> 116\u001b[0m     \u001b[43mwait_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m spin_cb \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    118\u001b[0m         spin_cb()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\uv\\data\\python\\cpython-3.10.18-windows-x86_64-none\\lib\\threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 324\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    326\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "query.awaitTermination(timeout=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fe1da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "query.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark-labs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
